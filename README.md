# Real-Time-Healthcare-Data-Processing-using-Databricks-Delta-Live-Tables
 
## **ğŸ“ Project Overview**  
This project implements a **real-time data processing pipeline** for healthcare data using **Databricks Delta Live Tables (DLT)**. The pipeline processes patient records in multiple stages (**Bronze, Silver, and Gold**) to ensure high data quality, efficient transformations, and readiness for analytics.  

## **ğŸš€ Features**  
- **Delta Live Tables (DLT):** Automates data transformation and lineage tracking.  
- **Multi-Layered Architecture:** Implements **Bronze (Raw), Silver (Cleansed), and Gold (Aggregated)** tables.  
- **Real-Time Data Ingestion:** Processes live patient data for timely insights.  
- **Optimized Performance:** Uses **Delta Tables** for fast querying and reduced storage costs.  
- **Scalable Workflow:** Runs on **Databricks** with **PySpark** for efficient execution.  

## **ğŸ› ï¸ Tech Stack**  
- ğŸŸ¢ **PySpark** â€“ Distributed data processing  
- ğŸ”£ **Databricks** â€“ Cloud-based data platform  
- ğŸ‘ˆ **Delta Tables** â€“ Optimized storage for faster queries  
- âš¡ **Delta Live Tables (DLT)** â€“ Automated ETL pipeline management  

## **ğŸ“‚ Project Structure**  
```
ğŸ’ƒ ETL Pipeline
 â”£ ğŸ’ƒ Code/
 â”ƒ â”£ ğŸ’ƒ healthcare_dlt_pipeline_notebook.sql
 â”ƒ â”£ ğŸ’ƒ spark_code_to_feed_tables.ipynb
 â”£ ğŸ’ƒ DLT Workflow.png         # Workflow diagram
 â”£ ğŸ’ƒ data/                    # Sample input data files
 â”ƒ â”£ ğŸ’ƒ diagnosis_mapping.csv
 â”ƒ â”£ ğŸ’ƒ patients_daily_file_1_2024.csv
 â”ƒ â”£ ğŸ’ƒ patients_daily_file_2_2024.csv
 â”ƒ â”£ ğŸ’ƒ patients_daily_file_3_2024.csv
 â”£ ğŸ’ƒ README.md                # Project documentation
```

## **âš™ï¸ Setup Instructions**  

### **1âƒ£ Clone the Repository**  
```bash
git clone https://github.com/your-username/healthcare-dlt-pipeline.git
cd healthcare-dlt-pipeline
```

### **2âƒ£ Upload to Databricks**  
- Create a **Databricks Notebook**.  
- Upload the scripts from the **notebooks/** folder.  
- Configure a **Delta Live Table pipeline** in Databricks.  

### **3âƒ£ Run the DLT Pipeline**  
- Navigate to **Workflows â†’ Delta Live Tables** in Databricks.  
- Create a new pipeline and attach the **Bronze, Silver, and Gold notebooks**.  
- Click **Start** to process data in real time.  

## **ğŸ“Š Data Pipeline Flow**  
1âƒ£ **Bronze Layer** â€“ Ingests raw healthcare data from sources (CSV, API, Streams).  
2âƒ£ **Silver Layer** â€“ Cleans and standardizes patient records.  
3âƒ£ **Gold Layer** â€“ Aggregates data for reporting & analytics.  

## **ğŸ¤ Contributing**  
Want to improve this project? Feel free to **fork** the repository, make changes, and submit a **pull request**.  
